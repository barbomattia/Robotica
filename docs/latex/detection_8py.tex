\hypertarget{detection_8py}{}\doxysection{/home/angelonutu/ros\+\_\+ws/src/\+Robotica/vision\+\_\+planner/src/vision\+\_\+planner/detection.py File Reference}
\label{detection_8py}\index{/home/angelonutu/ros\_ws/src/Robotica/vision\_planner/src/vision\_planner/detection.py@{/home/angelonutu/ros\_ws/src/Robotica/vision\_planner/src/vision\_planner/detection.py}}


Performs block detection based on pre-\/trained O\+N\+NX model and Open\+CV\textquotesingle{}s Deep Neural Network submodule.  


\doxysubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classvision__planner_1_1detection_1_1Detection}{vision\+\_\+planner.\+detection.\+Detection}}
\begin{DoxyCompactList}\small\item\em Main structure encapsulating all useful information about a single deteceted entity. \end{DoxyCompactList}\item 
class \mbox{\hyperlink{classvision__planner_1_1detection_1_1Image}{vision\+\_\+planner.\+detection.\+Image}}
\begin{DoxyCompactList}\small\item\em Structure to get input image for neural network. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
cv.\+dnn.\+Net \mbox{\hyperlink{detection_8py_ac996652bfe7aa7af9b5d6a679aaaaaa7}{vision\+\_\+planner.\+detection.\+load\+O\+N\+NX}} ()
\begin{DoxyCompactList}\small\item\em Load a neural network from an O\+N\+NX file. \end{DoxyCompactList}\item 
Image \mbox{\hyperlink{detection_8py_a52e9c13985ac4d984a08e144c64eefe5}{vision\+\_\+planner.\+detection.\+pad\+And\+Resize}} (cv.\+Mat frame)
\begin{DoxyCompactList}\small\item\em Resize and pad an input image to a square shape for compatibility with Y\+O\+L\+Ov8 network input. \end{DoxyCompactList}\item 
list \mbox{\hyperlink{detection_8py_a7361123c9a0b78a6c80f0ef3d3e26637}{vision\+\_\+planner.\+detection.\+inference}} (cv.\+Mat frame, cv.\+dnn.\+Net net)
\begin{DoxyCompactList}\small\item\em Performs inference on an image based on a pre-\/trained Y\+O\+L\+Ov8 neural network converted to O\+N\+NX. \end{DoxyCompactList}\item 
None \mbox{\hyperlink{detection_8py_a7d7cdbaeafdf5527964d9d636776db96}{vision\+\_\+planner.\+detection.\+show\+B\+Box}} (cv.\+Mat frame, list detections)
\begin{DoxyCompactList}\small\item\em Show on screen the image on which inference has been performed with the detections. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{detection_8py_adb884d107e5d0c82923b54bbbe115062}\label{detection_8py_adb884d107e5d0c82923b54bbbe115062}} 
string \mbox{\hyperlink{detection_8py_adb884d107e5d0c82923b54bbbe115062}{vision\+\_\+planner.\+detection.\+O\+N\+NX}} = \textquotesingle{}yolov8.\+onnx\textquotesingle{}
\begin{DoxyCompactList}\small\item\em Path to O\+N\+NX model. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{detection_8py_a7d2ee39ccb3d15c42ae547f1c7be3bbf}\label{detection_8py_a7d2ee39ccb3d15c42ae547f1c7be3bbf}} 
int \mbox{\hyperlink{detection_8py_a7d2ee39ccb3d15c42ae547f1c7be3bbf}{vision\+\_\+planner.\+detection.\+S\+Q\+U\+A\+RE}} = 640
\begin{DoxyCompactList}\small\item\em Size of network input. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{detection_8py_a6293857e7ff4e1064bc4663cda5fd85f}\label{detection_8py_a6293857e7ff4e1064bc4663cda5fd85f}} 
tuple \mbox{\hyperlink{detection_8py_a6293857e7ff4e1064bc4663cda5fd85f}{vision\+\_\+planner.\+detection.\+S\+I\+ZE}} = (S\+Q\+U\+A\+RE, S\+Q\+U\+A\+RE)
\begin{DoxyCompactList}\small\item\em XY size of network input. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{detection_8py_ae00adc6e075cf608c0a9091631d3a471}\label{detection_8py_ae00adc6e075cf608c0a9091631d3a471}} 
float \mbox{\hyperlink{detection_8py_ae00adc6e075cf608c0a9091631d3a471}{vision\+\_\+planner.\+detection.\+S\+C\+O\+R\+E\+T\+H\+R\+E\+SH}} = 0.\+25
\begin{DoxyCompactList}\small\item\em Threshold for confidence scores. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{detection_8py_a9f4a477441c3ec6383be994ed9d2507f}\label{detection_8py_a9f4a477441c3ec6383be994ed9d2507f}} 
float \mbox{\hyperlink{detection_8py_a9f4a477441c3ec6383be994ed9d2507f}{vision\+\_\+planner.\+detection.\+N\+M\+S\+T\+H\+R\+E\+SH}} = 0.\+50
\begin{DoxyCompactList}\small\item\em Non-\/\+Maximum Suppression threshold. \end{DoxyCompactList}\item 
list \mbox{\hyperlink{detection_8py_a8fac2cd10d176dabed674d0884371b0a}{vision\+\_\+planner.\+detection.\+class\+Names}}
\begin{DoxyCompactList}\small\item\em Classes of possibly detected objects. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{detection_8py_ac3a7faea5d1611ccee6dbb12c67ec2e3}\label{detection_8py_ac3a7faea5d1611ccee6dbb12c67ec2e3}} 
cv.\+dnn.\+Net {\bfseries vision\+\_\+planner.\+detection.\+net} = load\+O\+N\+NX()
\item 
\mbox{\Hypertarget{detection_8py_a52cc62f23918323d3dc17c1d81cc7d16}\label{detection_8py_a52cc62f23918323d3dc17c1d81cc7d16}} 
{\bfseries vision\+\_\+planner.\+detection.\+frame} = cv.\+imread(f\textquotesingle{}./photos/photo1.\+jpg\textquotesingle{})
\item 
\mbox{\Hypertarget{detection_8py_a0f1d5e5c73ac7870f1a435cf20c1912f}\label{detection_8py_a0f1d5e5c73ac7870f1a435cf20c1912f}} 
list {\bfseries vision\+\_\+planner.\+detection.\+detections} = inference(frame, net)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Performs block detection based on pre-\/trained O\+N\+NX model and Open\+CV\textquotesingle{}s Deep Neural Network submodule. 

\hypertarget{detection_8py_description_doxygen_example}{}\doxysubsection{Description}\label{detection_8py_description_doxygen_example}
Give overview\+: T\+O\+DO.\hypertarget{detection_8py_libraries_main}{}\doxysubsection{Libraries/\+Modules}\label{detection_8py_libraries_main}

\begin{DoxyItemize}
\item Open\+CV (\href{https://pypi.org/project/opencv-python/}{\texttt{ https\+://pypi.\+org/project/opencv-\/python/}})
\begin{DoxyItemize}
\item Pre-\/process the image to perform inference on.
\item Input the image to the network.
\item Get outputs of neural network.
\end{DoxyItemize}
\item Numpy (\href{https://numpy.org/}{\texttt{ https\+://numpy.\+org/}})
\begin{DoxyItemize}
\item Manage network output to extrapolate useful data. 
\end{DoxyItemize}
\end{DoxyItemize}

\doxysubsection{Function Documentation}
\mbox{\Hypertarget{detection_8py_a7361123c9a0b78a6c80f0ef3d3e26637}\label{detection_8py_a7361123c9a0b78a6c80f0ef3d3e26637}} 
\index{detection.py@{detection.py}!inference@{inference}}
\index{inference@{inference}!detection.py@{detection.py}}
\doxysubsubsection{\texorpdfstring{inference()}{inference()}}
{\footnotesize\ttfamily  list vision\+\_\+planner.\+detection.\+inference (\begin{DoxyParamCaption}\item[{cv.\+Mat}]{frame,  }\item[{cv.\+dnn.\+Net}]{net }\end{DoxyParamCaption})}



Performs inference on an image based on a pre-\/trained Y\+O\+L\+Ov8 neural network converted to O\+N\+NX. 

This function takes as input an image, pre-\/processes it to the required standards set by the neural network, and forward passes the blob to the D\+NN. Afterwards, it receives the outputs in Y\+O\+L\+Ov8 format \mbox{[}batch\+Size, 84, 8400\mbox{]} and processes them to extract meaningful data about the bounding boxes, class types, and confidence scores. Non-\/\+Maximum Suppression is then immediately applied to filter out possible overlapping or invalid bounding boxes, and a list of all successful detections is passed back.


\begin{DoxyParams}{Parameters}
{\em frame} & Input cv2 image to perform inference on. \\
\hline
{\em net} & Pre-\/trained loaded O\+N\+NX neural network for object detection.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
A list of Detection objects.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
The format \mbox{[}batch\+Size, 84, 8400\mbox{]} is interpreted as\+: 1 -\/ batch\+Size (should always be 1 since the inference is made on singular frames) 84 -\/ 0, 1, 2, 3 are the usual Y\+O\+LO bounding box \mbox{[}centerX, centerY, width, height\mbox{]}, the rest are the probabilities for each class 8400 -\/ number of possible detected objects

The classes are hard-\/coded; they can be replaced to work with a specific O\+N\+NX model.
\end{DoxyNote}
Example usage\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{nn = loadONNX()}
\DoxyCodeLine{input\_image = cv2.imread(\textcolor{stringliteral}{"path/to/image.jpeg"})}
\DoxyCodeLine{detections = inference(input\_image, nn)}
\end{DoxyCode}


\begin{DoxySeeAlso}{See also}
pad\+And\+Resize 

load\+O\+N\+NX 

\href{https://github.com/ultralytics/ultralytics/issues/2670}{\texttt{ Github issue}} about Y\+O\+L\+Ov8 output 
\end{DoxySeeAlso}
\mbox{\Hypertarget{detection_8py_ac996652bfe7aa7af9b5d6a679aaaaaa7}\label{detection_8py_ac996652bfe7aa7af9b5d6a679aaaaaa7}} 
\index{detection.py@{detection.py}!loadONNX@{loadONNX}}
\index{loadONNX@{loadONNX}!detection.py@{detection.py}}
\doxysubsubsection{\texorpdfstring{loadONNX()}{loadONNX()}}
{\footnotesize\ttfamily  cv.\+dnn.\+Net vision\+\_\+planner.\+detection.\+load\+O\+N\+NX (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Load a neural network from an O\+N\+NX file. 

This function loads a neural network model from an O\+N\+NX trained model file and configures it for inference. If C\+U\+D\+A-\/enabled G\+P\+Us are available, and C\+U\+DA runtime is built on the system, the function sets the backend and target to C\+U\+DA for faster inference. Otherwise, it defaults to C\+PU processing.

\begin{DoxyReturn}{Returns}
A cv2.\+dnn.\+Net object representing the loaded neural network.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
This is a hard-\/coded setup, hence the \textquotesingle{}yolov8.\+onnx\textquotesingle{} model is expected in the predefined folder
\end{DoxyNote}
Example usage\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{nn = loadONNX()}
\DoxyCodeLine{nn.setInput(blob)}
\DoxyCodeLine{nn.forward(results, nn.getUnconnectedLayersNames())}
\end{DoxyCode}


\begin{DoxySeeAlso}{See also}
cv2.\+dnn.\+read\+Net\+From\+O\+N\+NX 

cv2.\+cuda.\+get\+Cuda\+Enabled\+Device\+Count 
\end{DoxySeeAlso}
\mbox{\Hypertarget{detection_8py_a52e9c13985ac4d984a08e144c64eefe5}\label{detection_8py_a52e9c13985ac4d984a08e144c64eefe5}} 
\index{detection.py@{detection.py}!padAndResize@{padAndResize}}
\index{padAndResize@{padAndResize}!detection.py@{detection.py}}
\doxysubsubsection{\texorpdfstring{padAndResize()}{padAndResize()}}
{\footnotesize\ttfamily  Image vision\+\_\+planner.\+detection.\+pad\+And\+Resize (\begin{DoxyParamCaption}\item[{cv.\+Mat}]{frame }\end{DoxyParamCaption})}



Resize and pad an input image to a square shape for compatibility with Y\+O\+L\+Ov8 network input. 

This function takes an input image and resizes it to a square shape while maintaining the original aspect ratio. If the input image is different from a square shape, the aspect ratio is maintained and the rest of the image filled with zeroes (black pixels). Whichever the case, the image gets scaled to a specific square resolution.


\begin{DoxyParams}{Parameters}
{\em frame} & Input cv2 image to be resized and padded.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Processed image.
\end{DoxyReturn}
\begin{DoxyNote}{Note}
The scaled image size is hard-\/coded to cv2.\+Size(640, 640), needs to be changed if the network input expects another size
\end{DoxyNote}
Example usage\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{input\_image = cv2.imread(\textcolor{stringliteral}{"path/to/image.jpeg"})}
\DoxyCodeLine{input\_image = padAndResize(input\_image)}
\end{DoxyCode}
 \mbox{\Hypertarget{detection_8py_a7d7cdbaeafdf5527964d9d636776db96}\label{detection_8py_a7d7cdbaeafdf5527964d9d636776db96}} 
\index{detection.py@{detection.py}!showBBox@{showBBox}}
\index{showBBox@{showBBox}!detection.py@{detection.py}}
\doxysubsubsection{\texorpdfstring{showBBox()}{showBBox()}}
{\footnotesize\ttfamily  None vision\+\_\+planner.\+detection.\+show\+B\+Box (\begin{DoxyParamCaption}\item[{cv.\+Mat}]{frame,  }\item[{list}]{detections }\end{DoxyParamCaption})}



Show on screen the image on which inference has been performed with the detections. 

The function takes as input the image used for detection and the subsequent detections that the model has provided. Following this, bounding boxes are drawn on the image with the respective class names and confidence scores and shown on screen for any necessary assesment.


\begin{DoxyParams}{Parameters}
{\em frame} & Input cv2 image on which inference has been performed. \\
\hline
{\em detections} & list of Detection objects with data for all the detected blocks. ~\newline
\\
\hline
\end{DoxyParams}
Example usage\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{nn = loadONNX()}
\DoxyCodeLine{input\_image = cv2.imread(\textcolor{stringliteral}{"path/to/image.jpeg"})}
\DoxyCodeLine{detections = inference(input\_image, nn)}
\DoxyCodeLine{showBBox(input\_image, detections)}
\end{DoxyCode}


\begin{DoxySeeAlso}{See also}
pad\+And\+Resize 

load\+O\+N\+NX 

inference 
\end{DoxySeeAlso}


\doxysubsection{Variable Documentation}
\mbox{\Hypertarget{detection_8py_a8fac2cd10d176dabed674d0884371b0a}\label{detection_8py_a8fac2cd10d176dabed674d0884371b0a}} 
\index{detection.py@{detection.py}!classNames@{classNames}}
\index{classNames@{classNames}!detection.py@{detection.py}}
\doxysubsubsection{\texorpdfstring{classNames}{classNames}}
{\footnotesize\ttfamily list vision\+\_\+planner.\+detection.\+class\+Names}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{1 =  [}
\DoxyCodeLine{2     \textcolor{stringliteral}{"X1-\/Y1-\/Z2"},}
\DoxyCodeLine{3     \textcolor{stringliteral}{"X1-\/Y2-\/Z1"},}
\DoxyCodeLine{4     \textcolor{stringliteral}{"X1-\/Y2-\/Z2"},}
\DoxyCodeLine{5     \textcolor{stringliteral}{"X1-\/Y2-\/Z2-\/CHAMFER"},}
\DoxyCodeLine{6     \textcolor{stringliteral}{"X1-\/Y2-\/Z2-\/TWINFILLET"},}
\DoxyCodeLine{7     \textcolor{stringliteral}{"X1-\/Y3-\/Z2"},}
\DoxyCodeLine{8     \textcolor{stringliteral}{"X1-\/Y3-\/Z2-\/FILLET"},}
\DoxyCodeLine{9     \textcolor{stringliteral}{"X1-\/Y4-\/Z1"},}
\DoxyCodeLine{10     \textcolor{stringliteral}{"X1-\/Y4-\/Z2"},}
\DoxyCodeLine{11     \textcolor{stringliteral}{"X2-\/Y2-\/Z2"},}
\DoxyCodeLine{12     \textcolor{stringliteral}{"X2-\/Y2-\/Z2-\/FILLET"}}
\DoxyCodeLine{13 ]}

\end{DoxyCode}


Classes of possibly detected objects. 

